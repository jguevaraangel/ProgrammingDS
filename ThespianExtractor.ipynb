{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d45fde81-3997-46e7-b5fa-737b84d4a3f4",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "1. If you had not, install selenium using `pip install selenium webdriver-manager`\n",
    "2. If you had not, install tqdm using `pip install tqdm`\n",
    "3. instead of storing strings & numbers, or generic objects, it is wiser to store typed objects; two good choices are\n",
    "    1. __[namedtuple](https://docs.python.org/3/library/collections.html#collections.namedtuple)__\n",
    "    2. __[dataclass](https://docs.python.org/3/library/dataclasses.html)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f53d009c-2cfa-47be-ad50-e4222775ab0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from typing import Optional, List\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "httpHeaders = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Referer\": \"https://www.imdb.com/\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Upgrade-Insecure-Requests\": \"1\",\n",
    "}\n",
    "url = 'https://www.imdb.com/search/title/?title_type=tv_movie,feature&release_date=2024-01-01,2024-12-31&country_of_origin=IE'\n",
    "\n",
    "@dataclass\n",
    "class Director:\n",
    "    name: str\n",
    "    url: str\n",
    "\n",
    "@dataclass\n",
    "class Thespian:\n",
    "    name: str\n",
    "    url: str\n",
    "\n",
    "@dataclass\n",
    "class MovieInfo:\n",
    "    title: str\n",
    "    url: str\n",
    "    imdbRating: Optional[float] = None\n",
    "    imdbVotes: Optional[int] = None\n",
    "    metascore: Optional[int] = None\n",
    "    directors: List[str] = field(default_factory=list)\n",
    "    thespians: List[str] = field(default_factory=list)\n",
    "\n",
    "# Generic logger\n",
    "def logEvent(msg: str, level: str = \"INFO\", filePath: str = \"scrapingLog.log\") -> None:\n",
    "    timestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "    for line in msg.strip().splitlines():\n",
    "        with open(filePath, 'a') as f:\n",
    "            f.write(f\"{timestamp} [{level}] {line}\\n\")\n",
    "\n",
    "# Error logger shortcut\n",
    "def logError(msg: str, filePath: str = \"scrapingErrors.log\") -> None:\n",
    "    logEvent(msg, level=\"ERROR\", filePath=filePath)\n",
    "\n",
    "# Universal try-catcher with controllable flow\n",
    "def trierCatcher(keepGoing, traceMsg, task, *taskArgs, **taskKwargs):\n",
    "    if not keepGoing:\n",
    "        return (False, None)\n",
    "    try:\n",
    "        result = task(*taskArgs, **taskKwargs)\n",
    "        return (True, result)\n",
    "    except Exception as e:\n",
    "        logError(f\"{traceMsg}\\n{repr(e)}\")\n",
    "        return (False, None)\n",
    "\n",
    "# Extract movie info from current loaded page\n",
    "def tryParseMovieItem(item) -> Optional[MovieInfo]:\n",
    "    try:\n",
    "        titleBlock = item.select_one(\"div.dli-parent h3\")\n",
    "        if not titleBlock:\n",
    "            return None\n",
    "        title = titleBlock.text.strip()\n",
    "        anchor = item.select_one(\"a\")\n",
    "        if not anchor:\n",
    "            return None\n",
    "        url = \"https://www.imdb.com\" + anchor['href'].split('?')[0]\n",
    "\n",
    "        imdbRatingSpan = item.select_one(\"span.ipc-rating-star--rating\")\n",
    "        imdbVotesSpan = item.select_one(\"span.ipc-rating-star--voteCount\")\n",
    "        metascoreSpan = item.select_one(\"span.metacritic-score-box\")\n",
    "\n",
    "        imdbRating = imdbRatingSpan.text if imdbRatingSpan else None\n",
    "        imdbVotes = imdbVotesSpan.text if imdbVotesSpan else None\n",
    "        metascore = metascoreSpan.text if metascoreSpan else None\n",
    "\n",
    "        return MovieInfo(title=title, url=url, imdbRating=imdbRating, imdbVotes=imdbVotes, metascore=metascore)\n",
    "    except Exception as e:\n",
    "        logError(f\"Error parsing a movie item: {repr(e)}\")\n",
    "        return None\n",
    "\n",
    "def extractMoviesFromPage(pageSource: str) -> List[MovieInfo]:\n",
    "    soup = BeautifulSoup(pageSource, 'html.parser')\n",
    "    movieItems = soup.select(\"ul.ipc-metadata-list > li\")\n",
    "    movieBatch = []\n",
    "    for item in movieItems:\n",
    "        if len(item.attrs) == 1:\n",
    "            movie = tryParseMovieItem(item)\n",
    "            if movie:\n",
    "                movieBatch.append(movie)\n",
    "    return movieBatch\n",
    "\n",
    "def getBrowser(someURL):\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(someURL)\n",
    "    return driver    \n",
    "\n",
    "def scrapeIMDbMoviesWithSlidingWindow(someURL: str) -> List[MovieInfo]:\n",
    "    movieList = []\n",
    "    batchCounter = 0\n",
    "    defaultBatchSize = 50\n",
    "    pageBatchSize = 50\n",
    "    sleepTimeSeconds = 0.5\n",
    "    driverWaitTimeout = 10\n",
    "    keepGoing = True\n",
    "    nMoreButtonText = \"ipc-see-more__button\"\n",
    "    buttonTextRetrievalJSCommand = \"return arguments[0].innerText;\"\n",
    "    domPruningJSCommand = \"\"\"\n",
    "            const ul = document.querySelector(\"ul.ipc-metadata-list\");\n",
    "            const lis = ul.querySelectorAll(\"li\");\n",
    "            for (let i = 0; i < 50 && i < lis.length; i++) { lis[i].remove(); }\n",
    "        \"\"\"\n",
    "    clicketyJSCommand = \"arguments[0].click();\"\n",
    "    scrollJSCommand = \"arguments[0].scrollIntoView({block: 'center'});\"\n",
    "    metadataList = \"ipc-metadata-list-summary-item\"\n",
    "    pruningFailMsg = \"JS movie LI cleanup failure\"\n",
    "    movieExtractionFailMsg = \"Failed to extract movies from page\"\n",
    "    movieExtensionFailMsg = \"Failed to append new movies\"\n",
    "    clickFailMsg = \"Clickety failure\"\n",
    "    loadFailMsg = \"New movie load wait failure\"\n",
    "    scrollFailMsg = \"Scroll failure\"\n",
    "    batchSizeFailMsg = \"Batch size update failure\"\n",
    "    sleepFailMsg = \"Sleep failure\"\n",
    "    buttonFailMsg = \"Button retrieval failure\"\n",
    "    buttonTextFailMsg = \"Button text fetch failure\"\n",
    "    driver = getBrowser(someURL)\n",
    "\n",
    "    while keepGoing:\n",
    "        keepGoing, newMovies = trierCatcher(keepGoing, movieExtractionFailMsg, extractMoviesFromPage, driver.page_source)\n",
    "        keepGoing, _ = trierCatcher(keepGoing, movieExtensionFailMsg, movieList.extend, newMovies)\n",
    "        keepGoing, _ = trierCatcher(keepGoing, pruningFailMsg, driver.execute_script, domPruningJSCommand)\n",
    "        keepGoing, _ = trierCatcher(keepGoing, sleepFailMsg, time.sleep, sleepTimeSeconds)\n",
    "        keepGoing, button = trierCatcher(keepGoing, buttonFailMsg, WebDriverWait(driver, driverWaitTimeout).until, EC.element_to_be_clickable((By.CLASS_NAME, nMoreButtonText)))\n",
    "        keepGoing, buttonText = trierCatcher(keepGoing, buttonTextFailMsg, driver.execute_script, buttonTextRetrievalJSCommand, button)\n",
    "        keepGoing, _ = trierCatcher(keepGoing, scrollFailMsg, driver.execute_script, scrollJSCommand, button)\n",
    "        keepGoing, _ = trierCatcher(keepGoing, sleepFailMsg, time.sleep, sleepTimeSeconds)\n",
    "        keepGoing, _ = trierCatcher(keepGoing, clickFailMsg, driver.execute_script, clicketyJSCommand, button)\n",
    "        keepGoing, match = trierCatcher(keepGoing, batchSizeFailMsg, re.search, r\"(\\d+)\", buttonText)\n",
    "        pageBatchSize = int(match.group(1)) if keepGoing and match else defaultBatchSize\n",
    "        keepGoing, _ = trierCatcher(keepGoing, loadFailMsg, WebDriverWait(driver, driverWaitTimeout).until, lambda d: len(d.find_elements(By.CLASS_NAME, metadataList)) >= pageBatchSize)\n",
    "    driver.quit()\n",
    "    return movieList\n",
    "\n",
    "movies = scrapeIMDbMoviesWithSlidingWindow(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0be0058b-559a-4190-9acc-43ed62574e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapeMovieCredits(movieURL: str) -> tuple[List[Director], List[Thespian]]:\n",
    "    fullCreditsURL = movieURL + \"fullcredits/\"\n",
    "    directors = []\n",
    "    thespians = []\n",
    "    try:\n",
    "        response = requests.get(fullCreditsURL, headers=httpHeaders)\n",
    "        response.raise_for_status()\n",
    "    except Exception as e:\n",
    "        logError(f\"Failed to retrieve full credits page for {movieURL}\\n{repr(e)}\")\n",
    "        return (directors, thespians)\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # --- DIRECTORS ---\n",
    "    try:\n",
    "        director_section = soup.find(\"div\", attrs={\"data-testid\": \"sub-section-director\"})\n",
    "        if director_section:\n",
    "            ul = director_section.find(\"ul\")\n",
    "            if ul:\n",
    "                for li in ul.find_all(\"li\", recursive=False):\n",
    "                    anchor = li.find(\"a\", class_=\"name-credits--title-text-big\")\n",
    "                    if anchor:\n",
    "                        name = anchor.text.strip()\n",
    "                        url = \"https://www.imdb.com\" + anchor[\"href\"].split(\"?\")[0]\n",
    "                        directors.append(Director(name=name, url=url))\n",
    "    except Exception as e:\n",
    "        logError(f\"Failed parsing directors for {movieURL}\\n{repr(e)}\")\n",
    "        \n",
    "    # --- CAST (limited to top 5) ---\n",
    "    try:\n",
    "        cast_section = soup.find(\"div\", attrs={\"data-testid\": \"sub-section-cast\"})\n",
    "        if cast_section:\n",
    "            ul = cast_section.find(\"ul\")\n",
    "            if ul:\n",
    "                cast_lis = ul.find_all(\"li\", class_=\"full-credits-page-list-item\", recursive=False)[:5]\n",
    "                for li in cast_lis:\n",
    "                    anchor = li.find(\"a\", class_=\"name-credits--title-text-big\")\n",
    "                    if anchor:\n",
    "                        name = anchor.text.strip()\n",
    "                        url = \"https://www.imdb.com\" + anchor[\"href\"].split(\"?\")[0]\n",
    "                        thespians.append(Thespian(name=name, url=url))\n",
    "    except Exception as e:\n",
    "        logError(f\"Failed parsing cast for {movieURL}\\n{repr(e)}\")\n",
    "\n",
    "    return (directors, thespians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "702fd560-578f-47d6-8ec8-c0e374eb0ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, csv\n",
    "\n",
    "# Generic entity saver/loader functions\n",
    "def saveEntityListAsJSON(entities: List, filename: str):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump([asdict(e) for e in entities], f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def saveEntityListAsCSV(entities: List, filename: str):\n",
    "    if not entities:\n",
    "        return\n",
    "    with open(filename, 'w', encoding='utf-8', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=asdict(entities[0]).keys())\n",
    "        writer.writeheader()\n",
    "        for e in entities:\n",
    "            writer.writerow(asdict(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3203752-b784-4654-9d2e-5279b9d05ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import requests\n",
    "from collections import defaultdict\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import os\n",
    "\n",
    "def extractThespianAwards(html_content: str) -> dict:\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "    awards_data = defaultdict(lambda: {\"wins\": 0, \"nominations\": 0})\n",
    "\n",
    "    valid_awards = [\"oscar\", \"academy\", \"bafta\", \"goya\"]\n",
    "\n",
    "    for block in soup.find_all(\"a\", class_=\"ipc-metadata-list-summary-item__t\"):\n",
    "        full_text = block.get_text(strip=True).lower()\n",
    "        span = block.find(\"span\")\n",
    "        award_name = span.get_text(strip=True) if span else \"\"\n",
    "\n",
    "        if not any(key in award_name.lower() for key in valid_awards):\n",
    "            continue\n",
    "\n",
    "        normalized = next((name for name in [\"Oscar\", \"BAFTA\", \"Goya\"] if name.lower() in award_name.lower()), award_name)\n",
    "\n",
    "        if any(w in full_text for w in [\"ganador\", \"ganadora\", \"ganado\", \"won\", \"winner\"]):\n",
    "            awards_data[normalized][\"wins\"] += 1\n",
    "            awards_data[normalized][\"nominations\"] += 1\n",
    "        elif any(w in full_text for w in [\"nominado\", \"nominada\", \"nominación\", \"nominated\", \"nomination\"]):\n",
    "            awards_data[normalized][\"nominations\"] += 1\n",
    "\n",
    "    return dict(awards_data)\n",
    "    \n",
    "def collectThespianAwards(movies):\n",
    "    all_awards = []\n",
    "\n",
    "    for movie in tqdm(movies, desc=\"Movies\"):\n",
    "        for thespian in movie.thespians:\n",
    "            try:\n",
    "                url = thespian.url.rstrip(\"/\") + \"/awards\"\n",
    "                options = Options()\n",
    "                options.add_argument(\"--headless=new\")\n",
    "                options.add_argument(\"user-agent=Mozilla/5.0\")\n",
    "                driver = webdriver.Chrome(options=options)\n",
    "                driver.get(url)\n",
    "\n",
    "                try:\n",
    "                    category_buttons = driver.find_elements(By.CLASS_NAME, \"ipc-see-more__button\")\n",
    "                    for btn in category_buttons:\n",
    "                        try:\n",
    "                            section = btn.find_element(By.XPATH, \"ancestor::section\")\n",
    "                            section_text = section.text.lower()\n",
    "                            if any(k in section_text for k in [\"goya\", \"oscar\", \"bafta\"]):\n",
    "                                WebDriverWait(driver, 5).until(EC.element_to_be_clickable(btn))\n",
    "                                driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'})\", btn)\n",
    "                                #time.sleep(0.3)\n",
    "                                driver.execute_script(\"arguments[0].click();\", btn)\n",
    "                                #time.sleep(0.7)\n",
    "                        except:\n",
    "                            continue\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                html = driver.page_source\n",
    "                driver.quit()\n",
    "\n",
    "                awards = extractThespianAwards(html)\n",
    "                actor_data = {\n",
    "                    \"name\": thespian.name,\n",
    "                    \"url\": thespian.url,\n",
    "                    \"awards\": awards\n",
    "                }\n",
    "                all_awards.append(actor_data)\n",
    "            except Exception as e:\n",
    "                print(f\"Error con {thespian.name}: {e}\")\n",
    "                try:\n",
    "                    driver.quit()\n",
    "                except:\n",
    "                    pass\n",
    "            time.sleep(0.5)\n",
    "\n",
    "    return all_awards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a60a1b3-7c2a-4db0-8759-aa366b62d9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [03:30<00:00,  2.15s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "\n",
    "for movie in tqdm(movies):\n",
    "    directors, thespians = scrapeMovieCredits(movie.url)\n",
    "    movie.directors = directors\n",
    "    movie.thespians = thespians\n",
    "    time.sleep(0.5)  # Respect IMDb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f077b12-664d-4f3f-bdcd-2af9183eb350",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Movies:   3%|█████▏                                                                                                                                                                    | 3/98 [00:47<25:12, 15.92s/it]"
     ]
    }
   ],
   "source": [
    "thespianAwards = collectThespianAwards(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335f3ba2-0299-42f1-8704-4e8d267337f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (thespianAwards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ea96f7-f9b3-49b6-97e7-d37aa0e62f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Conda Base)",
   "language": "python",
   "name": "conda_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
